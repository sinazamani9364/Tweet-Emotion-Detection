{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6eJTtHUAlhG",
        "outputId": "f1887b76-2ab2-447a-dbde-1e81bad2a656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess"
      ],
      "metadata": {
        "id": "IiiDD063A1DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filename):\n",
        "  with open(filename) as file:\n",
        "      data = json.load(file)\n",
        "  return data"
      ],
      "metadata": {
        "id": "oO-36ztdBvM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "  sentences = []\n",
        "  for idx in data.keys():\n",
        "    sentences.extend(data[idx]['sentence_broken'])\n",
        "  tokenized_sentences = [simple_preprocess(sentence) for sentence in sentences]\n",
        "  return tokenized_sentences"
      ],
      "metadata": {
        "id": "Yp3kxnwEA9AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sadness_tweets = load_data('sadness_tweets.json')\n",
        "preprocessed_data = preprocess_data(sadness_tweets)\n",
        "\n",
        "model = Word2Vec(\n",
        "    preprocessed_data,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1\n",
        ")\n",
        "\n",
        "model.save('sadness.word2vec.bin')"
      ],
      "metadata": {
        "id": "aslPgcOcHhtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "happiness_tweets = load_data('happiness_tweets.json')\n",
        "preprocessed_data = preprocess_data(happiness_tweets)\n",
        "\n",
        "model = Word2Vec(\n",
        "    preprocessed_data,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1\n",
        ")\n",
        "\n",
        "model.save('happiness.word2vec.bin')"
      ],
      "metadata": {
        "id": "izAFQRH5Hhk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anger_tweets = load_data('anger_tweets.json')\n",
        "preprocessed_data = preprocess_data(anger_tweets)\n",
        "\n",
        "model = Word2Vec(\n",
        "    preprocessed_data,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1\n",
        ")\n",
        "\n",
        "model.save('anger.word2vec.bin')"
      ],
      "metadata": {
        "id": "uUsVZjFbHha6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fear_tweets = load_data('fear_tweets.json')\n",
        "preprocessed_data = preprocess_data(fear_tweets)\n",
        "\n",
        "model = Word2Vec(\n",
        "    preprocessed_data,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1\n",
        ")\n",
        "\n",
        "model.save('fear.word2vec.bin')"
      ],
      "metadata": {
        "id": "Muuq-Sy5HhRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disgust_tweets = load_data('disgust_tweets.json')\n",
        "preprocessed_data = preprocess_data(disgust_tweets)\n",
        "\n",
        "model = Word2Vec(\n",
        "    preprocessed_data,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1\n",
        ")\n",
        "\n",
        "model.save('disgust.word2vec.bin')"
      ],
      "metadata": {
        "id": "KvTQ34lGHhDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "surprise_tweets = load_data('surprise_tweets.json')\n",
        "preprocessed_data = preprocess_data(surprise_tweets)\n",
        "\n",
        "model = Word2Vec(\n",
        "    preprocessed_data,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1\n",
        ")\n",
        "\n",
        "model.save('surprise.word2vec.bin')"
      ],
      "metadata": {
        "id": "SPFhUIJ-Hg5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neutral_tweets = load_data('neutral_tweets.json')\n",
        "preprocessed_data = preprocess_data(neutral_tweets)\n",
        "\n",
        "model = Word2Vec(\n",
        "    preprocessed_data,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1\n",
        ")\n",
        "\n",
        "model.save('neutral.word2vec.bin')"
      ],
      "metadata": {
        "id": "MQBrDzO3HgrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tweets = load_data('all_tweets_preprocessed.json')\n",
        "preprocessed_data = preprocess_data(all_tweets)\n",
        "\n",
        "model = Word2Vec(\n",
        "    preprocessed_data,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1\n",
        ")\n",
        "\n",
        "model.wv.save_word2vec_format('all.word2vec.txt', binary=False)"
      ],
      "metadata": {
        "id": "euZxQXVHD8kN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}